{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "industrial-marriage",
   "metadata": {},
   "source": [
    "# **Regularización**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-haiti",
   "metadata": {},
   "source": [
    "## ¿Qué es la regularización?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-music",
   "metadata": {},
   "source": [
    "### La regularización se aplica básicamente para evitar la sobreoptimización de modelos. **Para aplicar estos métodos hay que estandarizar SI O SI.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-australian",
   "metadata": {},
   "source": [
    "#### **1. Técnica Ridge**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-tournament",
   "metadata": {},
   "source": [
    "## **Antes de aplicar la técnica Ridge haremos una regresión lineal de nuestros datos CON ESTANDARIZACIÓN INCLUÍDA.** Esto quiere decir que cogeremos X_train e y_train de la regresión lineal previa en la que ya los hemos estandarizado. Nada de crear nuevos X_train o y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-senator",
   "metadata": {},
   "source": [
    "**Ridge sirve para reducir todos los coeficientes de una regresión lineal** sin que ninguno de ellos llegue a cero. Esto **es útil para reducir mucho la sobreoptimización (overfitting) sin aumentar la infraoptimización (underfitting).** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-broad",
   "metadata": {},
   "source": [
    "Con este método, el coeficiente (la importancia) de nuestras variables **nunca llegará a cero,** lo que quiere decir que **ninguna variable será eliminada de la predicción.** Tendrán un coeficiente más alto (serán más importantes para predecir) o tendrán un coeficiente más bajo (serán menos importantes para predecir) pero su importancia nunca será 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-discretion",
   "metadata": {},
   "source": [
    "**1. Importamos el objeto Ridge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-arabic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-analyst",
   "metadata": {},
   "source": [
    "**2. Asigna el objeto Ridge a una variable con alpha = 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgeR = Ridge(alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-evaluation",
   "metadata": {},
   "source": [
    "**3. Entrena el objeto Ridge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgeR.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-apparatus",
   "metadata": {},
   "source": [
    "**4. Mira a ver como han quedado los coeficientes para alpha=1, puedes ir jugando con el alpha para cambiar estos valores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-colors",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coeficientes:\", ridgeR.coef_)\n",
    "print(\"Interceptor:\", ridgeR.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-louis",
   "metadata": {},
   "source": [
    "**5. Si te sirve puedes graficarlos para verlos mejor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-knowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize =(20, 10)) \n",
    "  \n",
    "color =['tab:gray', 'tab:blue', 'tab:orange',  \n",
    "'tab:green', 'tab:red', 'tab:purple', 'tab:brown',  \n",
    "'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan',  \n",
    "'tab:orange', 'tab:green', 'tab:blue', 'tab:olive'] \n",
    "  \n",
    "ax.bar(ridge_coefficient[\"Columns\"],  \n",
    "ridge_coefficient['Coefficient Estimate'],  \n",
    "color = color) \n",
    "  \n",
    "ax.spines['bottom'].set_position('zero') \n",
    "ax.set_ylim([-18,4])\n",
    "  \n",
    "plt.style.use('ggplot') \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-thesaurus",
   "metadata": {},
   "source": [
    "**6. Si te gustan los coeficientes asignados (o aunque no te gusten), ya puedes sacar predicciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-violence",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ridgeR.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-oregon",
   "metadata": {},
   "source": [
    "**7. Sacale el error medio cuadratico para ver si esto es basura o vale para algo.** Un error medio cuadrático de, por ejemplo, 10, indica que las predicciones se alejan 10 unidades de media respecto al real. Esto no está bien ni mal. Tienes que saber tú en que unidades trabajas y si esto es mucho o poco, el programa no va a hacer todo por tí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-asian",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error_ridge = np.mean((y_pred - y_test)**2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-mathematics",
   "metadata": {},
   "source": [
    "**Calculamos $r ^ 2$**\n",
    "\n",
    "$r^2$ nos indica que tan bien se ajusta nuestro modelo a la recta de regresión. Tendremos un $r^2$ y otro $r^2$ para el test.\n",
    "    \n",
    "    Cercano a 1 --> Buena mierda. Aunque a partir de 0.9 puede ser un overfitting de cuidao\n",
    "    \n",
    "    Cercano a 0 --> Not good sheit\n",
    "    \n",
    "   <img src=https://miro.medium.com/max/1472/0*8rFYfZJfJZpW2cEV.png alt=\"drawing\" style=\"width:350px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-groove",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.score(X_train_scal, y_train) * 100 # Entrenamiento\n",
    "lm.score(X_test_scal, y_test) * 100  # Test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
