{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "smart-native",
   "metadata": {},
   "source": [
    "# **Regularización**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-coordinate",
   "metadata": {},
   "source": [
    "## ¿Qué es la regularización?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-maldives",
   "metadata": {},
   "source": [
    "### La regularización se aplica básicamente para evitar la sobreoptimización de modelos. **Para aplicar estos métodos hay que estandarizar SI O SI.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-estimate",
   "metadata": {},
   "source": [
    "## Ridge nos va a servir de ayuda cuando sospechemos que varios de los atributos de entrada (features) estén correlados entre ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-success",
   "metadata": {},
   "source": [
    "#### **1. Técnica Ridge**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-background",
   "metadata": {},
   "source": [
    "## **Antes de aplicar la técnica Ridge haremos una regresión lineal de nuestros datos CON ESTANDARIZACIÓN INCLUÍDA.** Esto quiere decir que cogeremos X_train e y_train de la regresión lineal previa en la que ya los hemos estandarizado. Nada de crear nuevos X_train o y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-norfolk",
   "metadata": {},
   "source": [
    "**Ridge sirve para reducir todos los coeficientes de una regresión lineal** sin que ninguno de ellos llegue a cero. Esto **es útil para reducir mucho la sobreoptimización (overfitting) sin aumentar la infraoptimización (underfitting).** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-intermediate",
   "metadata": {},
   "source": [
    "Con este método, el coeficiente (la importancia) de nuestras variables **nunca llegará a cero,** lo que quiere decir que **ninguna variable será eliminada de la predicción.** Tendrán un coeficiente más alto (serán más importantes para predecir) o tendrán un coeficiente más bajo (serán menos importantes para predecir) pero su importancia nunca será 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-lightning",
   "metadata": {},
   "source": [
    "**1. Importamos el objeto Ridge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-multimedia",
   "metadata": {},
   "source": [
    "**2. Asigna el objeto Ridge a una variable donde alpha es una lista en escala logaritmica**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-hygiene",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgeR = RidgeCV(alpha=np.logspace(-10, 2, 200))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-wealth",
   "metadata": {},
   "source": [
    "**3. Entrena el objeto Ridge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgeR.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-planet",
   "metadata": {},
   "source": [
    "**4. Mira a ver como han quedado los coeficientes para la mejor alpha de todas las que le hemos pasado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-private",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coeficientes:\", ridgeR.coef_)\n",
    "print(\"Interceptor:\", ridgeR.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-driving",
   "metadata": {},
   "source": [
    " - También puedes ver que alpha ha seleccionado como la mejor de todas las que le hemos pasado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mejor valor de alpha encontrado: {ridgeR.alpha_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-outdoors",
   "metadata": {},
   "source": [
    "**5. Si te sirve puedes graficarlos para verlos mejor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-manufacturer",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize =(20, 10)) \n",
    "  \n",
    "color =['tab:gray', 'tab:blue', 'tab:orange',  \n",
    "'tab:green', 'tab:red', 'tab:purple', 'tab:brown',  \n",
    "'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan',  \n",
    "'tab:orange', 'tab:green', 'tab:blue', 'tab:olive'] \n",
    "  \n",
    "ax.bar(ridge_coefficient[\"Columns\"],  \n",
    "ridge_coefficient['Coefficient Estimate'],  \n",
    "color = color) \n",
    "  \n",
    "ax.spines['bottom'].set_position('zero') \n",
    "ax.set_ylim([-18,4])\n",
    "  \n",
    "plt.style.use('ggplot') \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-farming",
   "metadata": {},
   "source": [
    "**6. Si te gustan los coeficientes asignados (o aunque no te gusten), ya puedes sacar predicciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-dimension",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ridgeR.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-assignment",
   "metadata": {},
   "source": [
    "**7. Sacale el error medio cuadratico para ver si esto es basura o vale para algo.** Un error medio cuadrático de, por ejemplo, 10, indica que las predicciones se alejan 10 unidades de media respecto al real. Esto no está bien ni mal. Tienes que saber tú en que unidades trabajas y si esto es mucho o poco, el programa no va a hacer todo por tí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error_ridge = np.mean((y_pred - y_test)**2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-wagner",
   "metadata": {},
   "source": [
    "**Calculamos $r ^ 2$**\n",
    "\n",
    "$r^2$ nos indica que tan bien se ajusta nuestro modelo a la recta de regresión. Tendremos un $r^2$ y otro $r^2$ para el test.\n",
    "    \n",
    "    Cercano a 1 --> Buena mierda. Aunque a partir de 0.9 puede ser un overfitting de cuidao\n",
    "    \n",
    "    Cercano a 0 --> Not good sheit\n",
    "    \n",
    "   <img src=https://miro.medium.com/max/1472/0*8rFYfZJfJZpW2cEV.png alt=\"drawing\" style=\"width:350px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-accountability",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgeR.score(X_train_scal, y_train) * 100 # Entrenamiento\n",
    "ridgeR.score(X_test_scal, y_test) * 100  # Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-advocate",
   "metadata": {},
   "source": [
    "Entrenamiento y test tienen que dar más o menos parecido, sino has hecho un churro de puta madre, revisa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
