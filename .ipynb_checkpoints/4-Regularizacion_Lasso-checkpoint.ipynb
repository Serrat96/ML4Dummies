{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "alpine-enlargement",
   "metadata": {},
   "source": [
    "#### **2. Técnica Lasso**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-cowboy",
   "metadata": {},
   "source": [
    "**Para aplicar este método hay que estandarizar SI O SI.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-broadway",
   "metadata": {},
   "source": [
    "## **Antes de aplicar la técnica Lasso haremos una regresión lineal de nuestros datos CON ESTANDARIZACIÓN INCLUÍDA.** Esto quiere decir que cogeremos X_train e y_train de la regresión lineal previa en la que ya los hemos estandarizado. Nada de crear nuevos X_train o y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-patent",
   "metadata": {},
   "source": [
    "**Lasso sirve para reducir todos los coeficientes de una regresión lineal** pudiendo hacer que alguno de ellos llegue a cero. Esto **es útil para reducir mucho la sobreoptimización (overfitting) sin aumentar la infraoptimización (underfitting).** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-ebony",
   "metadata": {},
   "source": [
    "Con este método, el coeficiente (la importancia) de nuestras variables **llegará a cero,** lo que quiere decir que **algunas variables pueden ser (seguramente serán) eliminadas de la predicción.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-chapel",
   "metadata": {},
   "source": [
    "**1. Importamos el objeto Lasso**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-senegal",
   "metadata": {},
   "source": [
    "**2. Asigna el objeto Lasso a una variable con alpha = 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-score",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-boating",
   "metadata": {},
   "source": [
    "**3. Entrena el objeto Ridge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-likelihood",
   "metadata": {},
   "source": [
    "**4. Mira a ver como han quedado los coeficientes para alpha=1, puedes ir jugando con el alpha para cambiar estos valores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coeficientes:\", lasso.coef_)\n",
    "print(\"Interceptor:\", lasso.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-estonia",
   "metadata": {},
   "source": [
    "**5. Si te sirve puedes graficarlos para verlos mejor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-mounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize =(20, 10)) \n",
    "  \n",
    "color =['tab:gray', 'tab:blue', 'tab:orange',  \n",
    "'tab:green', 'tab:red', 'tab:purple', 'tab:brown',  \n",
    "'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan',  \n",
    "'tab:orange', 'tab:green', 'tab:blue', 'tab:olive'] \n",
    "  \n",
    "ax.bar(lasso_coefficient[\"Columns\"],  \n",
    "lasso_coefficient['Coefficient Estimate'],  \n",
    "color = color) \n",
    "  \n",
    "ax.spines['bottom'].set_position('zero') \n",
    "ax.set_ylim([-18,4])\n",
    "  \n",
    "plt.style.use('ggplot') \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-currency",
   "metadata": {},
   "source": [
    "**6. Si te gustan los coeficientes asignados (o aunque no te gusten), ya puedes sacar predicciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-recipient",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lasso.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-middle",
   "metadata": {},
   "source": [
    "**7. Sacale el error medio cuadratico para ver si esto es basura o vale para algo.** Un error medio cuadrático de, por ejemplo, 10, indica que las predicciones se alejan 10 unidades de media respecto al real. Esto no está bien ni mal. Tienes que saber tú en que unidades trabajas y si esto es mucho o poco, el programa no va a hacer todo por tí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error_ridge = np.mean((y_pred - y_test)**2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-algeria",
   "metadata": {},
   "source": [
    "**Calculamos $r ^ 2$**\n",
    "\n",
    "$r^2$ nos indica que tan bien se ajusta nuestro modelo a la recta de regresión. Tendremos un $r^2$ y otro $r^2$ para el test.\n",
    "    \n",
    "    Cercano a 1 --> Buena mierda. Aunque a partir de 0.9 puede ser un overfitting de cuidao\n",
    "    \n",
    "    Cercano a 0 --> Not good sheit\n",
    "    \n",
    "   <img src=https://miro.medium.com/max/1472/0*8rFYfZJfJZpW2cEV.png alt=\"drawing\" style=\"width:350px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-fiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.score(X_train_scal, y_train) * 100 # Entrenamiento\n",
    "lm.score(X_test_scal, y_test) * 100  # Test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
