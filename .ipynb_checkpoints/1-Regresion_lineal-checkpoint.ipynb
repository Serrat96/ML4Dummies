{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "presidential-enough",
   "metadata": {},
   "source": [
    "# **Instrucciones para Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-google",
   "metadata": {},
   "source": [
    "## **1. Regresión lineal**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-examination",
   "metadata": {},
   "source": [
    "Una regresión lineal trata de, **a partir de tu dataset, conseguir una ecuación como la de la imagen**\n",
    "\n",
    "<img src=http://3.bp.blogspot.com/-Vz2adH3zaeI/VTPq4T2rmDI/AAAAAAAABr4/K-ssPFWG8Tc/s1600/Regresion_ecuacion_2.jpg>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-cooking",
   "metadata": {},
   "source": [
    "1. Pasa los datos que tengas a DataFrame (a partir de aquí df) y explóralos anda, que igual ya tu solo sabes ver alguna relación, pollo.\n",
    "\n",
    "    Funciones útiles para esto:\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() / df.info() / df.describe() / df.corr() / df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-ranch",
   "metadata": {},
   "source": [
    "2. Hazle un análisis exploratorio de datos, que con **seaborn** son dos líneas, perro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)\n",
    "    \n",
    "sns.heatmap(df.corr(), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-disabled",
   "metadata": {},
   "source": [
    "3. **Los datos desde los que vas a predecir (features) los vas a rejuntar en una variable que se va a llamar X** (si, en mayúscula, cualquier duda pregúntale a Dani, yo no monté las pollas esas del CleanCode)\n",
    "    \n",
    "    **Los datos que quieres predecir (target) los vas rejuntar en un series llamado y** (si, en minúscula, yo que se por qué)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['columna_1', 'columna_2', 'columna_3', 'columna_n']]\n",
    "    \n",
    "y = df['columna_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-preliminary",
   "metadata": {},
   "source": [
    "4. **Importa el separador de datos y sepáralos** así entrenas el modelo como Dios manda, no me seas comunista, que no todo se puede mezclar con todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-collective",
   "metadata": {},
   "source": [
    "5. **Estandarizar variables.**\n",
    "\n",
    "    Importamos el standard scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "persistent-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-strap",
   "metadata": {},
   "source": [
    "    Creamos el objeto de estandarización, lo entrenamos y asignamos a una nueva variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scale = StandardScaler()\n",
    "std_scale.fit(X_train)\n",
    "\n",
    "X_train_scal = std_scale.transform(X_train)\n",
    "X_test_scal = std_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-poetry",
   "metadata": {},
   "source": [
    "#### A partir de aqui podemos empezar a hacer la regresión **¡OJO! X_train ha pasado a ser X_train_scal ya que está estandarizada y X_test ha pasado a ser X_test_scal** a partir de aquí usaremos **solo** X_train_scal y X_test_scal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-coverage",
   "metadata": {},
   "source": [
    "6. Importa el ~~logaritmo~~ algoritmo de regresión lineal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-flour",
   "metadata": {},
   "source": [
    "7. Crea el objeto de regresión y entrena el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-valentine",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression() -->Crear objeto\n",
    "    \n",
    "lm.fit(X_train_scal, y_train) -->Entrenar modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-local",
   "metadata": {},
   "source": [
    "8. Saca los coeficientes del modelo (opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-chuck",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lm.intercept_)\n",
    "    \n",
    "print(lm.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-treatment",
   "metadata": {},
   "source": [
    "    \n",
    "    Si quieres puedes representarlos en un DataFrame pa' echarles un ojo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-sympathy",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(lm_scal.coef_, X_train.columns, columns=['importance_standarized'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-mayor",
   "metadata": {},
   "source": [
    "    \n",
    "    Y ordénalos de mayor a menor tb (si quieres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-ethics",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.sort_values('importance_standarized', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-input",
   "metadata": {},
   "source": [
    "9. Predice lo que sea que tengas que predecir (X_test_scal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-bride",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lm.predict(X_test_scal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-mercy",
   "metadata": {},
   "source": [
    "La variable **predictions** es lo que tú has predecido, si la imprimes por pantalla tendrás tus predicciones en valor numérico. No te emociones porque si el dataset es muy grande no vas a poder evaluar con tu cerebro tanto dato. Por eso hace falta compararlos con los reales con un scatterplot para ver qué tanto se han ido de madre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-bachelor",
   "metadata": {},
   "source": [
    "10. **Grafica y_test frente a predictions**, así ves que tan precisa es tu predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y_test, predictions);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-hammer",
   "metadata": {},
   "source": [
    "11. **Saca un histograma de los residuales. Si pinta como una distribución normal esta aproximación vale.** Sino cambia a otra (o truca los datos, tu jefe no se va a enterar, bastante tiene con preguntar \"¿cómo va el proytecto?\" durante todo el día)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test - predictions);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-society",
   "metadata": {},
   "source": [
    "12. Grafica los tres errores más comunes:\n",
    "\n",
    "    - Error medio (MAE, in English)\n",
    "    \n",
    "    <img src=https://i.imgur.com/BmBC8VW.jpg alt=\"drawing\" style=\"width:500px;\"/>\n",
    "    \n",
    "    <img src=https://i.imgur.com/tqnei6J.jpg alt=\"drawing\" style=\"width:400px;\"/>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE', metrics.mean_absolute_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-theater",
   "metadata": {},
   "source": [
    "    - Error absoluto medio (MSE, in English)\n",
    "   \n",
    "   <img src=https://www.researchgate.net/profile/Alexandros-Karatzoglou/publication/221515860/figure/fig1/AS:339586132791298@1457975051470/Mean-Squared-Error-formula-used-to-evaluate-the-user-model.png alt=\"drawing\" style=\"width:350px;\"/>\n",
    "   \n",
    "   <img src=https://i.imgur.com/mLn8AeW.jpg alt=\"drawing\" style=\"width:350px;\"/>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-transportation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE', metrics.mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-victoria",
   "metadata": {},
   "source": [
    "    - Error cuadrático medio (RMSE, in English). Este es el error que mejor mide si el modelo está dando buenas previsiones.\n",
    "    \n",
    "   <img src=https://inteligenciaartificial.site/wp-content/uploads/2020/11/formular-cuadrada.png>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-chancellor",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RMSE', np.sqrt(metrics.mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-state",
   "metadata": {},
   "source": [
    "13. Calcular $r ^ 2$\n",
    "\n",
    "    $r^2$ nos indica que tan bien se ajusta nuestro modelo a la recta de regresión. \n",
    "    \n",
    "    Cercano a 1 --> Buena mierda. \n",
    "    \n",
    "    Cercano a 0 --> Not good sheit\n",
    "    \n",
    "   <img src=https://miro.medium.com/max/1472/0*8rFYfZJfJZpW2cEV.png alt=\"drawing\" style=\"width:350px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.score(X_train_scal, y_train) * 100 # Entrenamiento\n",
    "lm.score(X_test_scal, y_test) * 100  # Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-netscape",
   "metadata": {},
   "source": [
    "Entrenamiento y test tienen que dar más o menos parecido, sino has hecho un churro de puta madre, revisa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
